{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>The Extension for Stable Diffusion on AWS solution helps customers migrate their existing Stable Diffusion model training, inference, and finetuning workloads from on-premises servers to Amazon SageMaker using extension and CloudFormation template. By leveraging elastic resources in the cloud, it accelerates model iteration and avoids performance bottlenecks associated with single-server deployments.</p> <p>This implementation guide provides an overview of the solution, its reference architecture and components, considerations for planning the deployment, configuration steps for deploying the solution to the Amazon Web Services (AWS) Cloud. </p>"},{"location":"concepts/","title":"Concepts","text":"<p>This section describes key concepts and defines terminology specific to this solution: </p>"},{"location":"cost/","title":"Cost","text":"<p>You are responsible for the cost of AWS services used when running this solution. </p> <p>As of June 2023, for example, based on generating 1000 images per day and training Dreambooth 10 times as the benchmark, the estimated cost of using this solution in the US West (Oregon) (us-west-2) is $583 per month.</p> Service Usage Cost/Month AWS Lambda Generate 1000 images per day for inference, and an average Lambda runtime of 200ms, with a memory size of 1024MB $0.00 Amazon API Gateway Generate 1000 images per day for inference\uff0cwith an average of approximately 10 backend API calls per image, totaling 300,000 calls $0.30 Amazon Simple Storage Service (S3) 1000GB $23 Amazon DynamoDB 2GB storage $0.50 Step Functions Step function is used when deploying Amazon SageMaker Endpoint and model training\uff0c 600 calls of step function\uff0con average 15 state changes per workflow $0.13 Amazon CloudWatch writing 10GB of log data per month $5.04 Amazon Sagemaker Training Storage (General Purpose SSD (gp2)), Instance name (ml.g4dn.2xlarge), Number of training jobs per month (300), Number of instances per job (1), Hour(s) per instance per job (1) $282 Amazon Sagemaker Inference(GPU) Number of models per endpoint (1), Storage (General Purpose SSD (gp2)), Instance name (ml.g4dn.2xlarge), Number of instances per endpoint (1), Endpoint hour(s) per day (10), Endpoint day(s) per month (22), Number of models deployed (1) $206 Amazon Sagemaker Inference(CPU) Number of models per endpoint (1), Storage (General Purpose SSD (gp2)), Instance name (ml.r5.xlarge), Number of models deployed (1), Number of instances per endpoint (1), Endpoint hour(s) per day (10), Endpoint day(s) per month (22) $66 Total $583"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#general","title":"General","text":"<p>Q: What is Extension for Stable Diffusion on AWS?</p> <p>Extension for Stable Diffusion on AWS is an AWS solution that aims to assists customers migrate their Stable Diffusion model training, inference, and finetuning workloads on Stable Diffusion WebUI from local servers to Amazon SageMaker by providing extension and AWS CloudFormation template. By leveraging elastic cloud resources, this solution accelerates model iteration and mitigates performance bottlenecks associated with single-server deployments. </p> <p>Q: What are the native features/third-party extensions of Stable Diffusion WebUI supported by this solution?</p> <p>This solution supports multiply native features/third-party extensions of Stable Diffusion WebUI. More details can be found at Features and Benefits.</p> <p>Q: What is the licence of this solution?</p> <p>This solution is provided under the Apache-2.0 license. It is a permissive free software license written by the Apache Software Foundation. It allows users to use the software for any purpose, to distribute it, to modify it, and to distribute modified versions of the software under the terms of the license, without concern for royalties.</p> <p>Q: How can I submit a feature request or bug report?</p> <p>You can submit feature requests and bug report through the GitHub issues. Here are the templates for feature request, bug report.</p>"},{"location":"faq/#installation-and-configuration","title":"Installation and Configuration","text":"<p>Q: Is there a specific order for installing third-party plugins and the plugins for this solution?</p> <p>Currently, it is recommended that users install the third-party extensions supported by this solution before installing the solution's own extension. However, the installation order can be changed as well. In that case, a restart of the WebUI is required to ensure the successful functioning of the features.</p>"},{"location":"faq/#pricing","title":"Pricing","text":"<p>Q: How will I be charged and billed for the use of this solution?</p> <p>The solution is free to use, and you are responsible for the cost of AWS services used while running this solution. You pay only for what you use, and there are no minimum or setup fees. Refer to the Centralized Logging with OpenSearch Cost section for detailed cost estimation.</p>"},{"location":"notices/","title":"Notices","text":"<p>Customers are responsible for making their own independent assessment of the information in this document. This document: (a) is for informational purposes only, (b) represents Amazon Web Services current product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Amazon Web Services and its affiliates, suppliers or licensors. Amazon Web Services products or services are provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or implied. Amazon Web Services responsibilities and liabilities to its customers are controlled by Amazon Web Services agreements, and this document is not part of, nor does it modify, any agreement between Amazon Web Services and its customers.</p> <p>The Extension for Stable Diffusion on AWS solution is licensed under the terms of the Apache License Version 2.0 available at The Apache Software Foundation</p> <p>This guidance is for informational purposes only.  You should still perform your own independent assessment, and take measures to ensure that you comply with your own specific quality control practices and standards, and the local rules, laws, regulations, licenses and terms of use that apply to you, your content, and the third-party generative AI service referenced in this guidance.  Amazon Web Services has no control or authority over the third-party generative AI service referenced in this guidance, and does not make any representations or warranties that the third-party generative AI service is secure, virus-free, operational, or compatible with your production environment and standards. Amazon Web Services does not make any representations, warranties or guarantees that any information in this guidance will result in a particular outcome or result.   </p>"},{"location":"revisions/","title":"Revisions","text":"Date Change June 2023 Initial release"},{"location":"template/","title":"Template","text":"<p>To automate deployment, this solution uses the following AWS CloudFormation templates, which you can download before deployment:</p> <p>[xxx.template]: Use this template to launch the solution and all associated components. The default configuration deploys [Amazon API Gateway][api-gateway], [Amazon Lambda][lambda], [Amazon Batch][Batch], [Amazon S3][s3], [Amazon EFS][efs] and [Amazon Batch][Batch], but you can customize the template to meet your specific needs.</p>"},{"location":"uninstall/","title":"Uninstall Extension for Stable Diffusion on AWS","text":"<p>Warning</p> <p>Before uninstalling the solution, please manually delete all the Amazon SageMaker Endpoints deployed by this solution, referring to Delete deployed endpoint in Main tab. By uninstalling the solution, the DynamoDB tables that indicates the model training, finetuning and inference logs and mapping relationship, AWS Lambda related functions, AWS Step Functions and so on will be deleted simultaneously.</p> <p>To uninstall the Extension for Stable Diffusion on AWS solution, you must delete the AWS CloudFormation stack. </p> <p>You can use either the AWS Management Console or the AWS Command Line Interface (AWS CLI) to delete the CloudFormation stack.</p>"},{"location":"uninstall/#uninstall-the-stack-using-the-aws-management-console","title":"Uninstall the stack using the AWS Management Console","text":"<ol> <li>Sign in to the AWS CloudFormation console.</li> <li>Select this solution\u2019s installation parent stack.</li> <li>Choose Delete.</li> </ol>"},{"location":"uninstall/#uninstall-the-stack-using-aws-command-line-interface","title":"Uninstall the stack using AWS Command Line Interface","text":"<p>Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide. After confirming that the AWS CLI is available, run the following command.</p> <pre><code>aws cloudformation delete-stack --stack-name &lt;installation-stack-name&gt; --region &lt;aws-region&gt;\n</code></pre>"},{"location":"use-cases/","title":"Use cases","text":"<p>"},{"location":"architecture-overview/architecture-details/","title":"Architecture details","text":"<p>Diagram below is the brief view of internal workflow between offered extension and middleware, user will keep launching community WebUI onto standalone EC2/local server with our extension installed, while the ckpt merge, training and inference workload will be migrate onto AWS cloud through the RESTful API provided by middleware installed on user\u2019s AWS account. Note the middleware is per AWS account, means it could be installed separately as work node to communicate with WebUI as control node, user only need to input endpoint URL and API key per account to decide which specific AWS account will be used for successive jobs.</p> <p> Overall Workflow</p> <p>The middleware provides a RESTful API externally to comply with the OpenAPI specification to help WebUI extension to interact with AWS (Amazon SageMaker, S3, etc.). The main functions include request authentication, request distribution (such as SageMaker.jumpstart/model/predictor/estimator/tuner /utils, etc.), model training, model inference and other life cycle management work. The following figure shows the overall architecture of the middleware:</p> <p> Middleware Architecture</p> <ul> <li>Users in the WebUI console will use the assigned API token to trigger a request to API Gateway while being authenticated. (Note: AWS credentials are not required in AWS WebUI)</li> <li>API Gateway will route requests to Lambda with different functions according to URL prefixes to implement corresponding tasks (for example, model uploading, checkpoint merging), model training, and model inference. At the same time, the Lambda function records operational metadata into DynamoDB (eg, inferred parameters, model name) for subsequent query and correlation.</li> <li>During the training process, the Step Function will be called to orchestrate the training process, which includes using Amazon SageMaker for training and SNS for training status notification. During the inference process, the Lambda function will call Amazon SageMaker for asynchronous inference. Training data, models and checkpoints will be stored in S3 buckets separated by different prefixes.</li> </ul> <p>To keep container image of extension in sync with community, additional CI/CD pipeline (fig shown below) may needed to auto track community commits and pack &amp; build new container image, then user can easily launch latest extension without any manual operation.</p> <p> Image CI/CD Workflow</p>"},{"location":"architecture-overview/architecture/","title":"Architecture diagram","text":"<p>The overall architecture of the extension is composed of two components: the extension and the middleware. The extension is a WebUI extension that is installed on the community WebUI and responsible for providing a user interface for users to interact with the middleware. The middleware is a set of AWS resources that are deployed on the user's AWS account and responsible for providing RESTful APIs for the extension to interact with AWS resources. The whole solution provide a seamless experience for users to train and deploy models on AWS with following features:</p> <ul> <li>User Experience: Existing working flow is not changed, user can still use the community WebUI to train and deploy models with third-party extensions.</li> <li>Scalability: Existing workload including training and inference can be easily scaled and accelerated on Amazon SageMaker.</li> <li>Community: Provided extension is part of the community WebUI, which is open source and keeps evolving with the community.</li> </ul>"},{"location":"architecture-overview/design-considerations/","title":"Design considerations","text":"<p>This solution was designed with best practices from the AWS Well-Architected Framework which helps customers design and operate reliable, secure, efficient, and cost-effective workloads in the cloud. </p> <p>This section describes how the design principles and best practices of the Well-Architected Framework were applied when building this solution. </p>"},{"location":"deployment/deployment/","title":"Deployment step","text":"<p>Before you launch the solution, review the architecture, supported regions, and other considerations discussed in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account.</p> <p>Time to deploy: Approximately 25 minutes.</p>"},{"location":"deployment/deployment/#prerequisition","title":"Prerequisition","text":"<p>Users need to prepare a computer running linux system in advance.</p>"},{"location":"deployment/deployment/#deployment-overview","title":"Deployment overview","text":"<p>Use the following steps to deploy this solution on AWS. </p> <ul> <li>Step 1: Deploy Stable Diffusion WebUI. </li> <li>Step 2: Deploy the solution as a middleware.</li> <li>Step 3: Configure API url and API token.</li> </ul>"},{"location":"deployment/deployment/#deployment-steps","title":"Deployment steps","text":""},{"location":"deployment/deployment/#step-1-deploy-stable-diffusion-webui","title":"Step 1: Deploy Stable Diffusion WebUI.","text":"<ol> <li> <p>Download the CloudFormation Template from link</p> </li> <li> <p>Sign in to the AWS Management Console and go to CloudFormation console</p> </li> <li> <p>On the Stacks page, choose Create stack, and then choose With new resources (standard).</p> </li> <li> <p>On the Specify template page, choose Template is ready, choose Upload a template file, and then browse for the template that is downloaded in step 1, and then choose Next.</p> </li> <li> <p>On the Specify stack details page, type a stack name in the Stack name box. Choose an EC2 instance key pair, then choose Next.</p> </li> <li> <p>On the Configure stack options page, choose Next.</p> </li> <li> <p>On the Review page, review the details of your stack, and choose Submit.</p> </li> <li> <p>Wait until the stack is created.</p> </li> <li> <p>Find the output value of the CloudFormation stack, and navigate to the WebUI by clicking the link in the WebUIURL value, note you need to wait extra 5 minutes to wait for the internal setup complete after the stack been created successfully.</p> </li> </ol>"},{"location":"deployment/deployment/#step-2-deploy-the-solution-as-a-middleware","title":"Step 2: Deploy the solution as a middleware.","text":"<p>This automated AWS CloudFormation template deploys the solution in the AWS Cloud.</p> <ol> <li>Sign in to the AWS Management Console and use Launch solution in AWS Standard Regions to launch the AWS CloudFormation template.   </li> <li>The template will launch in the default region when you log into the console by default. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar.</li> <li>On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next.</li> <li> <p>On the Specify stack details page, assign a valid and account level unique name to your solution stack. Under Parameters, enter a valid bucket name under aigcbucketname for this solution to use, which is mainly for uploading dates and storing results. Enter a correct email address under email for future notice receiving. Enter a string of 20 characters that includes a combination of alphanumeric characters for sdextensionapikey, and it will be 09876543210987654321 by default. Select an instance type of Amazon EC2, which will mainly be used for operation including model creation, checkpoint merge, and etc. To select the tag for the ECR image corresponding to the solution, please refer to the ecrimagetag field (if no modification is needed, you can keep the default value). For specific tag explanations, please click on this link.Choose Next.</p> </li> <li> <p>On the Configure stack options page, choose Next.</p> </li> <li>On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack.</li> </ol> <p>You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately 15 minutes.</p> <p>Notice</p> <p>Please check the inbox of the email address you previously set up and click on the \"Confirm subscription\" hyperlink in the email with the subject \"AWS Notification - Subscription Confirmation\" to complete the subscription, and the message of 'Subscription confirmed!' appears.</p>"},{"location":"deployment/deployment/#step3-configure-api-url-and-api-token","title":"Step3: Configure API url and API token.","text":"<ol> <li> <p>Go to CloudFormation console.</p> </li> <li> <p>Select the root stack of the solution from the stack list, instead of a nested stack. Nested stacks in the list will be labeled as (NESTED) next to their names.</p> </li> <li> <p>Open the Outputs tab and locate the values corresponding to APIGatewayUrl and ApiGatewayUrlToken, and copy them.</p> </li> <li> <p>Open the Amazon SageMaker tab in the Stable Diffusion WebUI. Paste the URL obtained in step 3 into the API URL text box. Enter the token obtained in step 3 into the API Token field. Click Test Connection to receive a confirmation message of Successfully Connected.</p> </li> <li> <p>Click Update Setting to update the configuration file, so that you can receive the corresponding information next time.</p> </li> </ol>"},{"location":"deployment/ecr_image_param/","title":"How to modify the ECR image tag used in the solution","text":"<p>The current project uses the following three Public ECR images for training and inference: - public.ecr.aws/aws-gcr-solutions/stable-diffusion-aws-extension/aigc-webui-inference: TAG_NAME - public.ecr.aws/aws-gcr-solutions/stable-diffusion-aws-extension/aigc-webui-utils: TAG_NAME - public.ecr.aws/aws-gcr-solutions/stable-diffusion-aws-extension/aigc-webui-dreambooth-training: TAG_NAME</p> <p>The corresponding CDK deployment code can be found in: 1. infrastructure/src/common/dockerImages.ts</p> <pre><code>export const AIGC_WEBUI_INFERENCE: string = 'public.ecr.aws/aws-gcr-solutions/stable-diffusion-aws-extension/aigc-webui-inference:';\nexport const AIGC_WEBUI_UTILS: string = 'public.ecr.aws/aws-gcr-solutions/stable-diffusion-aws-extension/aigc-webui-utils:';\nexport const AIGC_WEBUI_DREAMBOOTH_TRAINING: string = 'public.ecr.aws/aws-gcr-solutions/stable-diffusion-aws-extension/aigc-webui-dreambooth-training:';\n</code></pre> <ol> <li>infrastructure/src/common/dockerImageTag.ts</li> </ol> <pre><code>export const ECR_IMAGE_TAG: string = 'dev';\n</code></pre> <p>TAG_NAME is defined by the CloudFormation deployment parameter <code>ecrimagetag</code>. By default, the tag value is dynamically generated during each compilation of the solution's CICD pipeline. For example, 'v1.0.0-46f9d43', where 'v1.0.0' represents the major version tag of the solution, and '46f9d43' is the commit ID of the project on GitHub.</p> <p>In most cases, users do not need to modify the ECR tag name. However, if users need to change the tag value, they can modify the default parameter value during the deployment of the solution's CloudFormation stack. Currently, we have two tag values available for users to choose from: 1. v1.0.0 2. v1.0.1-COMMITID</p> <p>```</p>"},{"location":"deployment/template/","title":"AWS CloudFormation template","text":"<p>To automate deployment, this solution uses the following AWS CloudFormation templates, which you can download before deployment:</p> <p>Extension for Stable Diffusion on AWS: Use this template to launch the solution and all associated components. The default configuration deploys Amazon API Gateway, AWS Lambda, Amazon S3, Amazon SageMaker and Amazon DynamoDB, but you can customize the template to meet your specific needs.</p>"},{"location":"developer-guide/source/","title":"Source code","text":"<p>Visit our GitHub repository to download the templates and scripts for this solution. The Extension for Stable Diffusion on AWS template is generated using the AWS Cloud Development Kit (CDK). Refer to the README.md file for additional information.</p>"},{"location":"plan-deployment/quotas/","title":"Quotas","text":"<p>To increase the quota of the Amazon SageMaker resources in your AWS account, you can follow these steps:</p> <ol> <li>Log in to the AWS Management Console and navigate to the Service Quotas console.</li> <li>Select AWS services from the navigation panel.</li> <li>Select Amazon SageMaker from the list, or type the service name in the search box.</li> <li>Request a quota increase: If the quota is adjustable, you can select the button or name, then select Request quota increase.</li> <li>Change the quota value: Enter the new value in the Change quota value field. The new value must be greater than the current value.</li> <li> <p>Submit the request: Click Request to submit your quota increase request to AWS.</p> <p>Notice</p> <p>Please note that some AWS services may only be available in certain regions. If you have quota increase requests in different regions, make sure to first select the appropriate region.</p> </li> </ol> <p>After you submit a quota increase request, you can track its status:</p> <ol> <li>View the request status: Return to the Service Quotas console and select Dashboard from the navigation panel. For pending requests, select the status of the request to open the request receipt. The initial status of the request is Pending. When the status changes to Quota Requested, you will see a case number at AWS Support. Select the case number to open your request receipt.</li> <li> <p>Check the quota request history: To view any pending or recently resolved requests, select Quota request history from the Service Quotas console navigation panel.</p> <p>Notice</p> <p>Kindly be noticed that quota increase requests do not receive priority support and may take some time to process. If you have an urgent request, consider contacting AWS Support directly.</p> </li> </ol> <p>Please refer to the following AWS documents for more information about quotas:</p> <ul> <li>Amazon SageMaker Service Quotas</li> <li>Requesting a Quota Increase</li> </ul>"},{"location":"plan-deployment/regions/","title":"Supported regions","text":"<p>As of June 2023, this solution is supported in the following Amazon Web Services Regions:</p> <ul> <li>us-east-1 (Virginia)</li> <li>us-east-2 (Ohio)  </li> <li>us-west-1 (N. California)</li> <li>us-west-2 (Oregon)  </li> <li>ca-central-1 (Canada) </li> <li>sa-east-1 (Sao Paulo)</li> <li>eu-west-1 (Ireland)</li> <li>eu-west-2 (London)</li> <li>eu-west-3 (Paris)   </li> <li>eu-central-1 (Frankfurt)  </li> <li>eu-north-1 (Stockholm)</li> <li>ap-northeast-1 (Tokyo) </li> <li>ap-northeast-2 (Seoul)  </li> <li>ap-northeast-3 (Osaka)</li> <li>ap-southeast-1 (Singapore)  </li> <li>ap-southeast-2 (Sydney)   </li> <li>ap-south-1 (Mumbai)  </li> <li>ap-east-1 (Hong Kong)</li> </ul> <p>Notice</p> <p>Recently, it's observed that newly created Amazon S3 bucket, in us-east-2, us-west-1, us-west-2, there is an issue with CORS that prevents users from uploading configuration files through the browser. Despite updating the CORS configuration, users frequently encounter CORS issues when uploading files using pre-signed URLs. The problem resolves itself after approximately two hours. We are currently in communication with the Amazon S3 Service team regarding this issue. According to that, it's recommended to deploy the solution in us-east-1, ap-northeast-1 or ap-southeast-1.</p>"},{"location":"plan-deployment/security/","title":"Security","text":"<p>When you build systems on AWS infrastructure, security responsibilities are shared between you and AWS. This shared model reduces your operational burden because AWS operates, manages, and controls the components including the host operating system, the virtualization layer, and the physical security of the facilities in which the services operate. For more information about AWS security, visit AWS Cloud Security.</p>"},{"location":"plan-deployment/security/#iam-roles","title":"IAM roles","text":"<p>AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s access between the solution components.</p>"},{"location":"plan-deployment/security/#security-groups","title":"Security groups","text":"<p>The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running.</p>"},{"location":"solution-overview/concepts/","title":"Concepts","text":"<p>This section describes key concepts and defines terminology specific to this solution: </p>"},{"location":"solution-overview/features-and-benefits/","title":"Features and benefits","text":""},{"location":"solution-overview/features-and-benefits/#features","title":"Features","text":"<p>This solution supports the cloud-based operations of the following native features/third-party extensions of Stable Diffusion WebUI:</p> Feature Supported Version Note txt2img V1.3.2 img2img V1.3.2 LoRa V1.2.1 ControlNet V1.1.217 Not support preprocessor 'inpaint_global_harmonious' Dreambooth V1.0.14 Image browser Latest"},{"location":"solution-overview/features-and-benefits/#benefits","title":"Benefits","text":"<ul> <li> <p>Convenient Installation: This solution leverages CloudFormation for easy deployment of AWS middleware. Combined with the installation of the native Stable Diffusion WebUI (WebUI) features and third-party extensions, users can quickly utilize Amazon SageMaker's cloud resources for inference, training and finetuning tasks.</p> </li> <li> <p>Community Native: This solution is implemented as an extension, allowing users to seamlessly use their existing WebUI without any changes. Additionally, the solution's code is open source and follows a non-intrusive design, enabling users to keep up with community-related feature iterations, such as popular plugins like Dreambooth, ControlNet, and LoRa.</p> </li> <li> <p>High Scalability: This solution decouples the WebUI interface from the backend, allowing the WebUI to launch on supported terminals without GPU restrictions. Existing training, inference, and other tasks can be migrated to Amazon SageMaker through the provided extension functionalities, providing users with elastic computing resources, cost reduction, flexibility, and scalability.</p> </li> </ul>"},{"location":"solution-overview/use-cases/","title":"Use cases","text":"<p>"},{"location":"user-guide/CloudAssetsManage/","title":"Main Tab","text":"<p>This chapter will provide a detailed overview of the convenient cloud-based resource management approach offered by this solution.</p>"},{"location":"user-guide/CloudAssetsManage/#upload-model","title":"Upload Model","text":"<p>To use extra models for inference, you will need to upload model through steps below, and follow steps in txt2img or img2imgto inference with extra models as need.</p> <ol> <li>Within Stable Diffusion WebUI, navigate to solution main tab Amazon SageMaker, find session Cloud Assets Management. </li> <li> <p>Enter the local model path under corresponding model text box. </p> <p>Note: You can upload multiple kinds of models by entering multiple local model paths in text box.</p> </li> <li> <p>Click Upload Models to Cloud to start uploading process.</p> </li> <li>Message will appear on left right once uploading completes.</li> </ol>"},{"location":"user-guide/CloudAssetsManage/#amazon-sagemaker-endpoint-management","title":"Amazon SageMaker Endpoint Management","text":""},{"location":"user-guide/CloudAssetsManage/#deploy-new-endpoint","title":"Deploy new endpoint","text":"<ol> <li>Within Stable Diffusion WebUI, navigate to solution main tab Amazon SageMaker, find session Cloud Assets Management, Deploy New SageMaker Endpoint, select Amazon SageMaker instance type for inference under SageMaker Instance Type, and count in Please select Instance count, click Deploy, message Endpoint deployment started will appear on the left side.</li> <li>You can navigate to tab txt2img, session Amazon SageMaker Inference, refresh and select drop down list Select Cloud SageMaker Endpoint to check all the deployment status of endpoints.     &gt; Note: The format of the drop down list is\uff1aendpoint name+ deployment status (including Creating/Failed/InService)+deployment completing time\u3002</li> <li>It will take around 10 mins for endpoint deployment status changing to InService, which indicates that the endpoint has been successfully deployed.</li> </ol>"},{"location":"user-guide/CloudAssetsManage/#delete-deployed-endpoints","title":"Delete deployed endpoints","text":"<ol> <li>Refresh and select endpoint(s) under dropdown list of Select Cloud SageMaker Endpoint.</li> <li>Click Delete, message Endpoint delete completed will appear on left side, which indicates that the selected endpoint(s) havs been successfully deleted.</li> </ol>"},{"location":"user-guide/dreambooth-guide/","title":"Dreambooth Guide","text":"<p>You can open Dreambooth tab, by combining the use with native Dreambooth, the tab Create from Cloud and Select from Cloud that newly added by the solution, you can achieve  cloud-based model creating and training in Dreambooth.</p>"},{"location":"user-guide/dreambooth-guide/#create-model","title":"Create Model","text":"<ol> <li>Open Dreambooth tab, Model subtab Create From Cloud. </li> <li> <p>Enter a model name in the Name text box.</p> <p>Notice</p> <p>Please note the naming format requirements: the name can only contain alphanumeric characters and dashes (\"-\").</p> </li> <li> <p>Select one checkpoint under Source Checkpoint dropdown list.</p> <p>Note\uff1a The checkpoint files here include two sources: files starting with \"local\" are locally stored checkpoint files, while those starting with \"cloud\" are checkpoint files stored on Amazon S3. For first-time use, it is recommended to select a local checkpoint file. </p> </li> <li>Click Create Model From Cloud to start model creation on cloud. Model Creation Jobs Details field will instantly update with the progress of the model creation job. When the status changes to Complete, it indicates that the model creation is finished.</li> </ol>"},{"location":"user-guide/dreambooth-guide/#train-model","title":"Train Model","text":"<ol> <li>Open Dreambooth tab, Model subtab, Select From Cloud.</li> <li>Fresh and select the model from Model dropd down list that need to train.</li> <li> <p>Set corresponding parameters in Input session.</p> <ul> <li>Set training parameters<ul> <li>Checking Lora can accelerate the training process.</li> <li>The Training Steps Per Image (Epochs) represents the number of iterations for training a single image and can be left at the default value.  </li> </ul> </li> <li>Set the concepts that need to be trained. A total of four concepts can be set, and we will use the first concept as an example.<ul> <li>In the Dataset Directory field, enter the path to the images required for training. It can be a path on a web server or an S3 path. For S3 paths, you can obtain them by uploading the data through AWS Dataset Management or by uploading them to S3 on your own. The path should start with \u201cs3://\".</li> <li>In the Instance Prompt section under Training Prompts, enter the keywords for the concept. These keywords will be used to generate the concept during the training process in txt2img. Therefore, avoid using common English words (as they might get confused with other concepts in the base model).</li> </ul> </li> </ul> <p> </p> <p>Notice</p> <p>You need to select the option to save the model to a subdirectory.</p> <p></p> <p>Notice</p> <p>Currently, it is not supported to save the Lora model separately. Please don't select the following option.</p> <p></p> </li> <li> <p>Click SageMaker Train to start model training task. The Training Job Details section will be updated in real-time with the status of the model training job. When the status changes to Complete, an email notification will be sent to the email address provided during the initial deployment of the solution, indicating that the model training is complete.</p> </li> <li>Future steps. For example: Navigate to txt2img tab Amazon SageMaker Inference panel, check trained model by refreshing Stable Diffusion Checkpoint dropdown list.  </li> </ol>"},{"location":"user-guide/img2img-guide/","title":"img2img Guide","text":"<p>You can open the img2img tab and use the original region along with the Amazon SageMaker Inference to perform inference on the cloud.</p>"},{"location":"user-guide/img2img-guide/#img2img-use-guide","title":"img2img use guide","text":""},{"location":"user-guide/img2img-guide/#standard-process-for-different-functional-labels-in-img2img","title":"Standard process for different functional labels in img2img","text":"<ol> <li>Navigate to tab img2img, open panel Amazon SageMaker Inference.</li> <li>Input parameters for inference. The same as local inferance, you could edit parameters in native fields for prompts, negative prompts, sampling parameters, inference parameters and etc. For functions img2img, sketch, inpaint, inpaint sketch and inpaint upload, you could upload and modify images in the native way.</li> <li> <p>Select the inference endpoint. Click the refresh button on the right side of Select Cloud SageMaker Endpoint to choose an inference endpoint that is in the InService state.</p> <p>Notice</p> <p>This field is mandatory. If you choose an endpoint that is in any other state or leave it empty, an error will occur when you click Generate on Cloud to initiate cloud-based inference.</p> </li> <li> <p>Fresh and select Stable Diffusion Checkpoint (required single select) and other extra models needed in Extra Networks for Cloud Inference (optional, multi-selection allowed).</p> </li> <li>ClickGenerate on Cloud\u3002</li> <li>Check inference result. Fresh and select the top option among Inference Job ID dropdown list. The Output section in the top-right area of the img2img tab will display the results of the inference once completed, including the generated images, prompts, and inference parameters. Based on this, you can perform subsequent workflows such as clicking Save or Send to extras. <p>Note: The list is sorted in reverse chronological order based on the inference time, with the most recent inference task appearing at the top. Each record is named in the format of inference time -&gt; job type(txt2img/img2img/interrogate_clip/interrogate_deepbooru) -&gt; inference status(succeed/in progress/fail) -&gt;inference id.</p> </li> </ol>"},{"location":"user-guide/img2img-guide/#img2img-label","title":"img2img label","text":"<ol> <li> <p>Upload the original image to img2img and enter prompts, for example black flower. </p> </li> <li> <p>Click Generate on Cloud, and select corresponding Inference Job ID, the generated image will present on the right Output session.  </p> </li> </ol>"},{"location":"user-guide/img2img-guide/#sketch-label","title":"Sketch label","text":"<ol> <li> <p>Start webui with \u2018--gradio-img2img-tool color-sketch\u2019 on the command line\uff0cupload the whiteboard background image to the Sketch tab. </p> </li> <li> <p>Use a brush to draw the corresponding sketch and prepare prompt words, for example flower. </p> </li> <li> <p>Click Generate on Cloud, and select corresponding Inference Job ID, the generated image will present on the right Output session. </p> </li> </ol>"},{"location":"user-guide/img2img-guide/#inpaint-label","title":"Inpaint label","text":"<ol> <li> <p>Upload original image to Inpaint label and prepare prompts, for example watermelon\u3002 </p> </li> <li> <p>Establish masks with brushes and prepare prompts, for example watermelon\u3002 </p> </li> <li> <p>Click Generate on Cloud, and select corresponding Inference Job ID, the generated image will present on the right Output session. </p> </li> </ol>"},{"location":"user-guide/img2img-guide/#inpatnt-sketch-label","title":"Inpatnt Sketch label","text":"<ol> <li> <p>Start webui with \u2018--gradio-img2img-tool color-sketch\u2019\uff0cand upload original image into Inpaint Sketchlabel with prompts, for example candy\u3002 </p> </li> <li> <p>Establish masks with brushes. </p> </li> <li> <p>Click Generate on Cloud, and select corresponding Inference Job ID, the generated image will present on the right Output session. </p> </li> </ol>"},{"location":"user-guide/img2img-guide/#inpatnt-upload-label","title":"Inpatnt Upload label","text":"<ol> <li> <p>Upload original image and mask image to Inpaint Upload label and prepare prompts, for example large eyes. </p> </li> <li> <p>Click Generate on Cloud, and select corresponding Inference Job ID, the generated image will present on the right Output session. </p> </li> </ol>"},{"location":"user-guide/img2img-guide/#interrogate-clipdeepbooru","title":"Interrogate clip/deepbooru","text":"<ol> <li>Navigate to img2img tab\uff0copen Amazon SageMaker Inference panel.</li> <li> <p>Interrogate only need to upload image to img2img tab. </p> </li> <li> <p>Select inference endpoint. Click refresh button on the right of Select Cloud SageMaker Endpoint, select one inference endpoint in InService state.</p> </li> <li>Click Interrogate CLIP on cloud or Interrogate DeepBooru on cloud.</li> <li>Check inference result. Refresh the dropdown list of Inference Job JDs, check the topmost Inference Job ID that match the inference submission timestamp to review the inference result. </li> </ol>"},{"location":"user-guide/img2img-guide/#continuous-inference-scenario","title":"Continuous Inference Scenario","text":"<ol> <li>Following the General Inference Scenario, complete the parameter inputs and click Generate on Cloud to submit the initial inference task.</li> <li>Wait for the appearance of a new Inference ID in the right-side Output section.</li> <li>Once the new Inference ID appears, you can proceed to click Generate on Cloud again for the next inference task. </li> </ol>"},{"location":"user-guide/preparation/","title":"Connet Stable Diffusion WebUI with AWS Account","text":""},{"location":"user-guide/preparation/#prerequisites","title":"Prerequisites","text":"<p>You need to have successfully completed the deployment of the solution.</p>"},{"location":"user-guide/preparation/#steps","title":"Steps","text":"<ol> <li>Visit AWS CloudFormation Console.</li> <li>Select the root stack of the solution you created from stack list, rather than the nested stacks. The nested stacks will be indicated as 'NESTED' next to their names in the list.</li> <li>Open Outputs tab, find URL of APIGatewayUrl and copy\u3002</li> <li>Open Stable Diffusion WebUI, nagivate to Amazon SageMakertab\uff0cpaste the URL copied from step 3 under API URL. Paste API token copied from step 3 into field of API Token. Click Update Setting\uff0cconfig updated to local config! message will appear. </li> <li>Click Test Connection, Successfully Connected message will appear, which indicates that Stable Diffusion WebUI has been successfully connected with AWS account of the backend deployed stack.</li> </ol>"},{"location":"user-guide/txt2img-guide/","title":"txt2img Guide","text":"<p>You can open the txt2img tab to perform text-to-image inference using the combined functionality of the native region of txt2img and the newly added \"Amazon SageMaker Inference\" panel in the solution. This allows you to invoke cloud resources for txt2img inference tasks.</p>"},{"location":"user-guide/txt2img-guide/#instructino-for-using-txt2img","title":"Instructino for using txt2img","text":""},{"location":"user-guide/txt2img-guide/#general-inference-scenario","title":"General Inference Scenario","text":"<ol> <li>Navigate to txt2img tab, open Amazon SageMaker Inference panel.  </li> <li>Enter the required parameters for inference. Similar to local inference, you can customize the inference parameters of the native txt2img, including prompts, negative prompts, sampling parameters, and inference parameters.</li> <li> <p>Select an endpoint for inference. Refresh and select an endpoint from Select Cloud SageMaker Endpoint dropdown list that is in the InService state.</p> <p>Notice</p> <p>This field is mandatory. If you choose an endpoint that is in any other state or leave it empty, an error will occur when you click Generate on Cloud to initiate cloud-based inference.</p> </li> <li> <p>Fresh and select Stable Diffusion Checkpoint (required single select) and other extra models needed in Extra Networks for Cloud Inference (optional, multi-selection allowed).</p> </li> <li>Click Generate on Cloud.</li> <li>Check inference result. Fresh and select the top option among Inference Job ID dropdown list. The Output section in the top-right area of the txt2img tab will display the results of the inference once completed, including the generated images, prompts, and inference parameters. Based on this, you can perform subsequent workflows such as clicking Save or Send to img2img. <p>Note\uff1a The list is sorted in reverse chronological order based on the inference time, with the most recent inference task appearing at the top. Each record is named in the format of inference time -&gt; inference id.</p> </li> </ol> <p></p>"},{"location":"user-guide/txt2img-guide/#continuous-inference-scenarios","title":"Continuous Inference Scenarios","text":"<ol> <li>Following the General Inference Scenario, complete the parameter inputs and click Generate on Cloud to submit the initial inference task.</li> <li>Wait for the appearance of a new Inference IDin the right-side \"Output\" section.</li> <li>Once the new Inference ID appears, you can proceed to click Generate on Cloud again for the next inference task.</li> </ol>"},{"location":"user-guide/txt2img-guide/#controlnet-guide","title":"Controlnet Guide","text":"<ul> <li>Open ControlNet panel, check Enable, select openpose from Preprocessor, and then upload am image. </li> <li>Open Amazon SageMaker Inferencepanel, select one checkpoint from Stable Diffusion Checkpoint and one model from ControlNet-Model. For example: below is the ineference based on v1-5-pruned-emaonly.safetensors and control_openpose-fp16.safetensors, prompts a cute dog, click Generate on Cloud. </li> <li>Refresh and select the top Inference Job from Inference Job IDs, inference result will be displayed in Output section.</li> </ul>"},{"location":"user-guide/txt2img-guide/#openpose-use-guide","title":"openpose use guide","text":""}]}